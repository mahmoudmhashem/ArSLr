{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from helper_functions import *\n",
    "\n",
    "model = torch.jit.load('../assests/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "video_npy_ls = []\n",
    "\n",
    "potential_label = \"None\"\n",
    "current_label = \"None\"\n",
    "live = 0\n",
    "try:\n",
    "    with PoseLandmarker.create_from_options(pose_options) as poselandmarker:\n",
    "        with HandLandmarker.create_from_options(hand_options) as handlandmarker:\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frame_timestamp_ms = int(cap.get(cv2.CAP_PROP_POS_MSEC))\n",
    "                frame_npy = frame2npy(frame, frame_timestamp_ms, poselandmarker, handlandmarker)\n",
    "                video_npy_ls.append(frame_npy)\n",
    "\n",
    "                frame_npy = np.expand_dims(frame_npy, (0, 1))\n",
    "                frame_npy_tensor = torch.from_numpy(frame_npy)\n",
    "                \n",
    "                frame_npy_tensor = frame_npy_tensor.to(model.device)\n",
    "                frame_npy_tensor = frame_npy_tensor.to(torch.float32)\n",
    "\n",
    "\n",
    "                label = model.predict(frame_npy_tensor)['labels'][0]\n",
    "\n",
    "                if label == potential_label:\n",
    "                    live+=1\n",
    "                else:\n",
    "                    potential_label = label\n",
    "                    live = 0\n",
    "                \n",
    "                if live > 5:\n",
    "                    current_label = potential_label\n",
    "\n",
    "                frame = cv2.flip(frame, 1)\n",
    "                cv2.rectangle(frame, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "                cv2.putText(frame, current_label, (3,30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "                # Show to screen\n",
    "                cv2.imshow('OpenCV Feed', frame)\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                \n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "except Exception as e:\n",
    "    # print(\"Error\", e)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()     \n",
    "    raise e       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
